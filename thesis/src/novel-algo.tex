\chapter{Novel Approaches}
\label{ch:novel-algos}
We now have a concept of what an \enquote{explainable} edge label looks like, so we propose new ideas for decomposing \DFAs such that the resulting \orDecomp has a good structure, precision, and size, resulting in good labels, understandable for humans.
Additionally, we want the algorithm to be able to handle outliers of a given \orDecomp, which might result in even shorter labels.
If we have a \orDecomp where a small factor covers most of the original \DFA, but not all of it, we need either a larger factor or remember the uncovered values, which could increase explainability.

\section{Greedy Short Factors}
\label{ch:novel-algos:greedy-short-factors}
Searching for a decomposition using only the maximal divisors of $|Q|$, provides good solutions in \LogSpace, but there are certain limitations.
Consider for example Figure \ref{fig:short-factors} depicting the \DFA $A$ with its factors $A_2$ and $A_4$.
Since for this \DFA, $|Q| = 8$, the only maximal divisor is 4 so the factor $A_4$ will be found by the original algorithm.
In this particular example, there exists a smaller factor with size 2, $A_2$ which will only be found if all factors of $|Q|$ are checked instead of only the maximal divisors.

\begin{figure}[h]
	\begin{minipage}[t]{\textwidth}
		\centering
		\begin{tikzpicture}[shorten >=1pt,node distance=1.5cm,on grid,auto] 
			\node[state,initial] (q_0)   {$q_0$}; 
			\node[state,accepting,fill=lightgray,fill opacity=0.5] (q_1) [ right=of q_0] {$q_1$}; 
			\node[state] (q_2) [ right=of q_1] {$q_2$}; 
			\node[state,accepting,fill=lightgray,fill opacity=0.5] (q_3) [ right=of q_2] {$q_3$};
			\node[state](q_4) [ right=of q_3] {$q_4$};
			\node[state,accepting,fill=lightgray,fill opacity=0.5] (q_5) [ right=of q_4] {$q_5$};
			\node[state] (q_6) [ right=of q_5] {$q_6$};
			\node[state,accepting,fill=lightgray,fill opacity=0.5] (q_7) [ right=of q_6] {$q_7$};
			\path[->] 
			(q_0) edge  node {} (q_1)
			(q_1) edge  node {} (q_2)
			(q_2) edge  node {} (q_3)
			(q_3) edge  node {} (q_4)
			(q_4) edge  node {} (q_5)
			(q_5) edge  node {} (q_6)
			(q_6) edge  node {} (q_7)
			(q_7) edge[bend right, above]  node {} (q_0);
		\end{tikzpicture}		
	\end{minipage}
	\begin{minipage}[b]{0.39\textwidth}
		\centering
		\begin{tikzpicture}[shorten >=1pt,node distance=1.5cm,on grid,auto] 
			\node[state,initial] (q_0)   {$q_0$}; 
			\node[state,accepting,fill=lightgray,fill opacity=0.5] (q_1) [right=of q_0] {$q_1$}; 
			\path[->] 
			(q_0) edge  node {} (q_1)
			(q_1) edge[bend right, above]  node {} (q_0);
		\end{tikzpicture}
	\end{minipage}
	\begin{minipage}[b]{0.59\textwidth}
		\centering
		\begin{tikzpicture}[shorten >=1pt,node distance=1.5cm,on grid,auto] 
			\node[state,initial] (q_0)   {$q_0$}; 
			\node[state,accepting,fill=lightgray,fill opacity=0.5] (q_1) [right=of q_0] {$q_1$}; 
			\node[state](q_2) [right=of q_1] {$q_2$};
			\node[state,accepting,fill=lightgray,fill opacity=0.5](q_3) [right=of q_2] {$q_3$};
			\path[->] 
			(q_0) edge  node {} (q_1)
			(q_1) edge  node {} (q_2)
			(q_2) edge  node {} (q_3)
			(q_3) edge[bend right, above]  node {} (q_0);
		\end{tikzpicture}
	\end{minipage}
	\caption{The DFA $A$ and its factors $A_2$ \& $A_4$}
	\label{fig:short-factors}
\end{figure}

Usually, the algorithms and proofs consider unary \DFAs consisting of a chain leading into a cycle of states.
Since we obtain our \DFAs by transforming from a periodic label, we only have \DFAs with empty chains, therefore only considering unary permutation \DFA.
This allows us to use a slightly simplified version of the Algorithm~3 from \cite{DBLP:journals/corr/abs-2107-04683} as visible in our Algorithm~\ref{algo:novel-greedy} as we do not encounter unary automata with $\sigma(q, uv) \not = \sigma(q, vu)$, and we want to compute an \orDecomp.
Instead of iterating over all potential sets of words $2^\mathcal{W}$ from $\mathcal{W} = \{a^{|Q|/p_i} | 1 \geq i \geq m\}$, we iterate over divisors of $|Q|$ and generate possible factors.
For each divisor $d$ we call the method \textit{getFactor} and generate the potential factor $A_d$, where $Q'$ is the set of equivalence classes $[p]$ of the states $p \in Q$, $\sigma'$ is defined as $a \in \Sigma$ we have that $\sigma'([p], a) = [\sigma(p, a)]$.
Iterating over all states of the factor in the method \textit{allAccepting}, we check if we are in a finial state and if all states folded onto the state $\sigma(q_I, a^{i})$ are also final in the original \DFA.
If this is the case, we include it in the final states of the current factor.
We are not only interested in answering the yes/no question of the composite problem but we want to collect the factors and continue our computation.
After all possible factors are computed, they are added greedily to the decomposition, in the order of their length, until no further changes occur.
\begin{algorithm}[h]
	\DontPrintSemicolon
	\SetKwProg{Fn}{Function}{:}{}
	\Fn{findGreedyComposite($A = \{{a}, Q, q_I , \sigma, F \}$: unary DFA)}{
		Decomposition $\gets \emptyset$\; 
		\ForEach{$A' \in$ getAllFactors($A$)}{
			\If{factorChangesComposite($A, A'$)}{
				Decomposition.add($A'$)
			}
		}
		\KwRet Decomposition\;
	}
	
	\Fn{getAllFactors($A = \{{a}, Q, q_I , \sigma, F \}$: unary DFA)}{
		FactorList $\gets \emptyset$\; 
		\ForEach{divisor $d$ of $|Q|$}{
			FactorList.add(getFactor($A$,$d$))
		}
		\KwRet FactorList\;
	}
	
	\Fn{getFactor($A = \{{a}, Q, q_I , \sigma, F \}$: unary DFA, integer $d$)}{
		$F' \gets \emptyset$\;
		$A_d \gets \{{a}, Q', [q_d] , \sigma', F' \}$\;
		\ForEach{$i \in [1,d]$}{
			\If{$\sigma(q_I,a^i) \in F$ and allAccepting($A,i,d$)}{
				$F' \gets F' \cup \sigma(q_I, a^{i})$
			}
		}
		\KwRet $A_d$
	}
	\Fn{allAccepting($A = \{{a}, Q, q_I , \sigma, F \}$: unary DFA, integer $d$, integer $i$)}{
		$pos \gets (i + d) ~mod~ |Q|$\;
		\While{$pos \not= i$}{
			\If{$\sigma(q_I, a^{pos}) \not\in F$}{
				\KwRet false\;
			}
			$pos \gets (pos + d) ~mod~ |Q|$
		}
	    \KwRet true\;
	}
	\caption{Algorithm for greedily computing an \orDecomp for unary DFAs and returning the factors.}
	\label{algo:novel-greedy}
\end{algorithm}
This algorithm finds more factors than required since it also finds the divisors of the maximal divisors.
In contrast, not all found factors are required to form the decomposition and we only want to add factors, which change the decomposition.
In our example in Figure \ref{fig:short-factors} we find $A_2$ and $A_4$, but $A_2$ is fully sufficient for decomposing the \DFA $A$.
By iterating over all possible factors ordered by size, we can greedily add factors, that cover accepting states that have not yet been covered.
The details of the method \textit{factorChangesComposite($A,A'$)} are omitted, as it simply checks if the addition of the factor produces a decomposition with fewer outliers than currently present.
To address the problem that most of the labels do not have proper decompositions in the mathematical sense, we will also consider a set of smaller automata that do not cover every value of a decomposition.
For this, we want to keep track of the outliers of each factor of the decomposition and the outliers of decomposition itself.
Regarding explainability, it should be of preference, to have a small factor but a couple of outliers, in comparison to a long factor, and even have a decomposition with hard outliers, e.g. values that cannot be covered by a decomposition.
In this case, a decomposition including outliers is also preferred.

\section{Problem Generalization}
The original problem was solvable in \LogSpace, but by extending the problem to finding the shortest possible factors, we face a different challenge.
Finding a valid decomposition is possible in \LogSpace but selecting a minimal amount of given factors needed to be a valid decomposition is not.
This problem can be generalized for picking a minimal decomposition from a given set of factors as follows:
\begin{defn}[\sc{Select Factors Decomposition}]{\ \\}
	Input: A set of binary strings $\mathcal{W} = \{w_1, w_2, \dots, w_n\}$ with $\ell(w_i) < l$ and $\ell(w_i)$ divides $l$ for $1 \leq i \leq n$, a binary string $u$ with $\ell(u)= l$ and an integer $k$.\\
	Question: Exists indices $i_1, i_2, \dots i_k$ such that
	$$w_{i_1}^{l / \ell(w_{i_1})} \lor w_{i_2}^{l / \ell(w_{i_2})} ~\dots~ \lor w_{i_k}^{l / \ell(w_{i_k})} = u $$
\end{defn}

To find lower bounds for this novel problem, we are going to reduce the {\sc{Set Cover}} problem, known to be NP-complete, to our novel {\sc{Select Factors Decomposition}} problem, using a polynomial time reduction.

\begin{defn}[\sc{Set Cover}]{\ \\}
	Input: A set of elements $U = \{u_1, u_2, \dots , u_n\}$, a set $\mathcal{C} = \{C_1, C_2, \dots , C_m\}$ where $C_i \subseteq U ~\forall~ C_i \in \mathcal{C}$ and an integer $k$.\\
	Question: Exists a set $\mathcal{O} \subseteq \mathcal{C}$ of size  at most $k$ such that $\underset{C_i \in \mathcal{O}}{\bigcup}C_i = U$.
\end{defn}
To reduce the {\sc{Set Cover}} problem to our novel problem, we create an instance as follows.
For the universe $U = \{u_1, u_2, \dots, u_n\}$ we will construct a binary string $u= 1^{2|U|}$ with length $\ell(u) = 2|U|$.
For each subset of $\mathcal{C} = \{C_1, C_2, \dots, C_m\}$ we create a word $w_i$ such that $w_i[j] = 1$ iff $u_j \in C_i$. 

Assume a solution to the {\sc{Select Factors Decomposition}} problem $i_1, i_2, \dots, i_k$ that chooses from the words $w_i$ to form $u$, then the respective subsets $C_{i_1}, C_{i_2}, \dots, C_{i_k}$ in the constructed {\sc{Set Cover}} instance cover the entire universe $U$.
Assume there exists an element $u_x \in U$ with $u_x \not \in C_{i_k} ~\forall~ i_1, i_2, \dots, i_k$.
This implies that there is no $w_{i_k} ~\forall~ i_1, i_2, \dots, i_k$ with $w_{i_k}[x]=1$ which is in contradiction to the found solution with $w_{i_1}^{l / \ell(w_{i_1})} \lor w_{i_2}^{l / \ell(w_{i_2})} ~\dots~ \lor w_{i_k}^{l / \ell(w_{i_k})} = u = 1^{2|U|}$.
This means that $u_x$ cannot exist and we found a {\sc{Set Cover}} of size $k$.
If the {\sc{Set Cover}} problem has a solution $\mathcal{O} = \lbrace C_{i_1}, C_{i_2}, \dots, C_{i_k} \rbrace$ with $\bigcup_{C_i \in \mathcal{O}} C_i = U$, then $w_{i_1}^{l / \ell(w_{i_1})} \lor w_{i_2}^{l / \ell(w_{i_2})} ~\dots~ \lor w_{i_k}^{l / \ell(w_{i_k})}$ is a solution to the {\sc{Select Factors Decomposition}} problem.
Assume $w_{i_1}^{l / \ell(w_{i_1})} \lor w_{i_2}^{l / \ell(w_{i_2})} ~\dots~ \lor w_{i_k}^{l / \ell(w_{i_k})} \not = u$, that implies there is at least one position $x$ where $(w_{i_1}^{l / \ell(w_{i_1})} \lor w_{i_2}^{l / \ell(w_{i_2})} ~\dots~ \lor w_{i_k}^{l / \ell(w_{i_k})})[x] \not= u[x] $.
This is in contradiction to the construction as there has to be a $C_{i_x} \in \mathcal{O}$ with $u_x \in C_{i_x}$ and therefore a word $w_{i_x}$ with $w_{i_x}[x]=1$. This reduction demonstrates that solving the {\sc{Select Factors Decomposition}} problem is as hard as solving the {\sc{Set Cover}} problem.

\section{Fourier Transform}
\label{ch:novel-algos:fourier}
Finding shorter factors than just the maximal divisors should already increase the explainability but consider the following example from Figure \ref{fig:fourier-transform-a}.
Factor $A_4$ alone would suffice to cover the original \DFA $A$ but most of the final states are already covered by the smaller factor $A_2$.
Consider the states $q_1, q_3 q_5$ and $q_7$ which are covered by both factors, which is not required for the decomposition to be valid.
We can remove all the states from $A_4$ which are already covered by $A_2$ and this results in 2 Factors with each having just one final state.
Of course, there might be multiple states which are not part of any other smaller factors, but any factor of an \orDecomp can be replaced by multiple factors of the same length, each with $|F_{B_i}| = 1 ~\forall~ (B_i)_{1 \leq i \leq k}$.
Each factor only having a single final state further increases explainability as it allows for each value to be represented as the position and the size of the factor or the periodicity, e.g.~instead of a binary label, a list of integer tuples could represent the label.
For a comparison between single or multiple binary labels and a list of tuples with the factors, a detailed examination including human-computer interaction would be required.

\begin{figure}[h]
	\begin{minipage}[t]{\textwidth}
		\centering
		\begin{tikzpicture}[shorten >=1pt,node distance=1.5cm,on grid,auto] 
			\node[state,initial] (q_0)   {$q_0$}; 
			\node[state,accepting,fill=lightgray,fill opacity=0.5] (q_1) [ right=of q_0] {$q_1$}; 
			\node[state,accepting,fill=lightgray,fill opacity=0.5] (q_2) [ right=of q_1] {$q_2$}; 
			\node[state,accepting,fill=lightgray,fill opacity=0.5] (q_3) [ right=of q_2] {$q_3$};
			\node[state](q_4) [ right=of q_3] {$q_4$};
			\node[state,accepting,fill=lightgray,fill opacity=0.5] (q_5) [ right=of q_4] {$q_5$};
			\node[state,accepting,fill=lightgray,fill opacity=0.5] (q_6) [ right=of q_5] {$q_6$};
			\node[state,accepting,fill=lightgray,fill opacity=0.5] (q_7) [ right=of q_6] {$q_7$};
			\path[->] 
			(q_0) edge  node {} (q_1)
			(q_1) edge  node {} (q_2)
			(q_2) edge  node {} (q_3)
			(q_3) edge  node {} (q_4)
			(q_4) edge  node {} (q_5)
			(q_5) edge  node {} (q_6)
			(q_6) edge  node {} (q_7)
			(q_7) edge[bend right, above]  node {} (q_0);
		\end{tikzpicture}		
	\end{minipage}
	\begin{minipage}[b]{0.39\textwidth}
		\centering
		\begin{tikzpicture}[shorten >=1pt,node distance=1.5cm,on grid,auto] 
			\node[state,initial] (q_0)   {$q_0$}; 
			\node[state,accepting,fill=lightgray,fill opacity=0.5] (q_1) [right=of q_0] {$q_1$}; 
			\path[->] 
			(q_0) edge  node {} (q_1)
			(q_1) edge[bend right, above]  node {} (q_0);
		\end{tikzpicture}
	\end{minipage}
	\begin{minipage}[b]{0.59\textwidth}
		\centering
		\begin{tikzpicture}[shorten >=1pt,node distance=1.5cm,on grid,auto] 
			\node[state,initial] (q_0)   {$q_0$}; 
			\node[state,accepting,fill=lightgray,fill opacity=0.5] (q_1) [right=of q_0] {$q_1$}; 
			\node[state,accepting,fill=lightgray,fill opacity=0.5](q_2) [right=of q_1] {$q_2$};
			\node[state,accepting,fill=lightgray,fill opacity=0.5](q_3) [right=of q_2] {$q_3$};
			\path[->] 
			(q_0) edge  node {} (q_1)
			(q_1) edge  node {} (q_2)
			(q_2) edge  node {} (q_3)
			(q_3) edge[bend right, above]  node {} (q_0);
		\end{tikzpicture}
	\end{minipage}
	\caption{The DFA $A$ and its overlapping factors $A_2$ \& $A_4$}
	\label{fig:fourier-transform-a}
\end{figure}

\begin{figure}[h]
\begin{minipage}[b]{0.39\textwidth}
	\centering
	\begin{tikzpicture}[shorten >=1pt,node distance=1.5cm,on grid,auto] 
		\node[state,initial] (q_0)   {$q_0$}; 
		\node[state,accepting,fill=lightgray,fill opacity=0.5] (q_1) [right=of q_0] {$q_1$}; 
		\path[->] 
		(q_0) edge  node {} (q_1)
		(q_1) edge[bend right, above]  node {} (q_0);
	\end{tikzpicture}
\end{minipage}
\begin{minipage}[b]{0.59\textwidth}
	\centering
	\begin{tikzpicture}[shorten >=1pt,node distance=1.5cm,on grid,auto] 
		\node[state,initial] (q_0)   {$q_0$}; 
		\node[state] (q_1) [right=of q_0] {$q_1$}; 
		\node[state,accepting,fill=lightgray,fill opacity=0.5](q_2) [right=of q_1] {$q_2$};
		\node[state](q_3) [right=of q_2] {$q_3$};
		\path[->] 
		(q_0) edge  node {} (q_1)
		(q_1) edge  node {} (q_2)
		(q_2) edge  node {} (q_3)
		(q_3) edge[bend right, above]  node {} (q_0);
	\end{tikzpicture}
\end{minipage}
\caption{The Fourier transformed factors $A_2$ \& $A_4$}
\label{fig:fourier-transform-b}
\end{figure}
Of course, this would also greatly increase the amount of factors required for a valid decomposition, and in turn, could hurt performance.
In general, the greedy approach of combining factors of increasing size should still suffice.

\section{Relaxation of Requirements}
\label{ch:novel-algos:relaxation}
So far we only considered decompositions where the union over all factors $B_i$ results in exactly the original language, $L(A) = \cup_{1\leq i \leq k} L(B_i)$, and all factors $B_i$ in the decomposition satisfy $|B_i| < |A|$.
Since our goal is not to find decompositions of minimal width but to find decomposition such that the explainability is maximized, we can relax the requirements to achieve greater explainability.
If we allow for factors of original size $|B_i| \leq |A|$, we can find a factor of the original size, which covers all values not covered by a factor so far.
The values only covered by this final factor $B_k$ but not by any other factor, can be considered hard outliers and it allows for a decomposition of any \DFA.
This might not make much sense for \DFAs but it makes sense in the context of explainable labels.
Additionally, we may allow for $L(A) \supseteq \cup_{1\leq i \leq k} L(B_i)$ and use the precision for a decomposition with $L(A) \not = \cup_{1\leq i \leq k} L(B_i)$ as $precision(\cup_{1\leq i \leq k}~ B_i) = \frac{|F_A| - out(\{B_1\dots B_k\})}{|F_A|}$ used in the metric, and allow for a decomposition to be valid if a certain precision is reached.

\section{Delta Window as Preprocessing or During Folding}
\label{ch:novel-algos:delta-window}
Working with real-world data always poses a challenge as the dataset might be very large or contain measurement errors.
The longer a label and therefore the corresponding automata gets, it becomes less and less likely that a valid folding of the automata exists.
To mitigate this problem, we implemented a delta window during the folding step of the algorithm.
The delta window during folding does not change the input, but instead, a folding is considered valid, if a set value folds onto another by some delta window.
Formally, with applied delta window of width $w$, a state $q_i$ is final in the input, if there exists a $q_j \in F$ with $j \in \lbrace ((i - w)~mod~|Q|), \dots, ((i + w)~mod~|Q|) \rbrace$.
The effectiveness of the delta window approach will be evaluated in Section \ref{ch:Evaluation:explainability}.

\section{EPG Creation from Decomposition}
\label{ch:novel-algos:ept-graph}

In the last step, our goal is to create an EPG instance by combining decompositions across all labels.
For each edge and its corresponding label, we gather all factors from the computed \orDecomp and substitute them with multiple edges, each representing a factor.
Ideally, the resulting edge labels should be smaller than the original label.
In cases of severe outliers, an alternative representation must be introduced. This can take the form of the original label, serving as a fallback for outliers, or as a list where an edge is included whenever the current time step $t~mod$ the original label length equals an element in the list.
While this method becomes less efficient with numerous hard outliers, it could still be an improvement compared to using a lengthy label.


%%% Local Variables: 
%%% mode: latex
%%% TeX-master: "thesis"
%%% End: 