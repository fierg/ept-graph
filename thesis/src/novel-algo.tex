\chapter{Novel Approaches}
\label{chap:novel-algos}
We now have a concept of what an \enquote{explainable} edge label looks like, so we propose new ideas for decomposing \DFAs such that the resulting \orDecomp has a good structure, precision, and size, resulting in good labels, understandable for humans.
Additionally, we want the algorithm to be able to handle outliers of a given \orDecomp, which might result in even shorter labels.
If we have a \orDecomp where a small factor covers most of the original \DFA, but not all of it, we need either a larger factor or remember the uncovered values, which could increase explainability.

\section{Greedy Short Factors}
\label{ch:novel-algos:greedy-short-factors}
Searching for a decomposition using only the maximal divisors of $|Q|$, provides good solutions in \LogSpace, but there are certain limitations.
Consider for example Figure \ref{fig:short-factors} depicting the trivial \DFA $A$ with its factors $A_2$ and $A_4$.
Since for this \DFA, $|Q| = 8$, the only maximal divisor is 4 so the factor $A_4$ will be found by the original algorithm.
In this particular example, there exists a smaller factor with size 2, $A_2$ which will only be found if checking all factors of $|Q|$ instead of only the maximal divisors.

\begin{figure}[h]
	\begin{minipage}[t]{\textwidth}
		\centering
		\begin{tikzpicture}[shorten >=1pt,node distance=1.5cm,on grid,auto] 
			\node[state,initial] (q_0)   {$q_0$}; 
			\node[state,accepting] (q_1) [ right=of q_0] {$q_1$}; 
			\node[state] (q_2) [ right=of q_1] {$q_2$}; 
			\node[state,accepting] (q_3) [ right=of q_2] {$q_3$};
			\node[state](q_4) [ right=of q_3] {$q_4$};
			\node[state,accepting] (q_5) [ right=of q_4] {$q_5$};
			\node[state] (q_6) [ right=of q_5] {$q_6$};
			\node[state,accepting] (q_7) [ right=of q_6] {$q_7$};
			\path[->] 
			(q_0) edge  node {} (q_1)
			(q_1) edge  node {} (q_2)
			(q_2) edge  node {} (q_3)
			(q_3) edge  node {} (q_4)
			(q_4) edge  node {} (q_5)
			(q_5) edge  node {} (q_6)
			(q_6) edge  node {} (q_7)
			(q_7) edge[bend right, above]  node {} (q_0);
		\end{tikzpicture}		
	\end{minipage}
	\begin{minipage}[b]{0.39\textwidth}
		\centering
		\begin{tikzpicture}[shorten >=1pt,node distance=1.5cm,on grid,auto] 
			\node[state,initial] (q_0)   {$q_0$}; 
			\node[state,accepting] (q_1) [right=of q_0] {$q_1$}; 
			\path[->] 
			(q_0) edge  node {} (q_1)
			(q_1) edge[bend right, above]  node {} (q_0);
		\end{tikzpicture}
	\end{minipage}
	\begin{minipage}[b]{0.59\textwidth}
		\centering
		\begin{tikzpicture}[shorten >=1pt,node distance=1.5cm,on grid,auto] 
			\node[state,initial] (q_0)   {$q_0$}; 
			\node[state,accepting] (q_1) [right=of q_0] {$q_1$}; 
			\node[state](q_2) [right=of q_1] {$q_2$};
			\node[state,accepting](q_3) [right=of q_2] {$q_3$};
			\path[->] 
			(q_0) edge  node {} (q_1)
			(q_1) edge  node {} (q_2)
			(q_2) edge  node {} (q_3)
			(q_3) edge[bend right, above]  node {} (q_0);
		\end{tikzpicture}
	\end{minipage}
	\caption{The DFA $A$ and its factors $A_2$ \& $A_4$}
	\label{fig:short-factors}
\end{figure}

Usually, the algorithms and proofs consider unary \DFAs consisting of a chain leading into a cycle of states.
Since we obtain our \DFAs by transforming from a periodic label, we only have \DFAs with empty chains, therefore only considering unary permutation \DFA.
This allows us to use a slightly simplified version of the Algorithm from \cite{DBLP:journals/corr/abs-2107-04683} as seen in Algorithm \ref{algo:composite} as we do not encounter unary automata with $\sigma(q, uv) \not = \sigma(q, vu)$, and we want to compute an \orDecomp.
Instead of iterating over all potential sets of words $2^\mathcal{W}$, we iterate over the input states and generate possible factors.
Additionally we are not only interested in answering the yes/no question of the composite problem but we want to collect the factors and continue our computation.
After all possible factors are computed, they are added greedily to the composite, in the order of their length, until no further changes occur.

\begin{algorithm}[h]
	\label{algo:composite}
	\DontPrintSemicolon
	\SetKwProg{Fn}{Function}{:}{}
	\Fn{findGreedyComposite($A = \{{a}, Q, q_I , \sigma, F \}$: unary DFA)}{
		Decomposition $\gets \emptyset$\; 
		\ForEach{$A' \in$ getAllFactors($A$)}{
			\If{factorChangesComposite($A, A'$)}{
				Decomposition.add($A'$)
			}
		}
		\KwRet Decomposition\;
	}
	
	\Fn{getAllFactors($A = \{{a}, Q, q_I , \sigma, F \}$: unary DFA)}{
		FactorList $\gets \emptyset$\; 
		\ForEach{divisor $d$ of $|Q|$}{
			FactorList.add(getFactor($A$,$d$))
		}
		\KwRet FactorList\;
	}
	
	\Fn{getFactor($A = \{{a}, Q, q_I , \sigma, F \}$: unary DFA, integer $d$)}{
		$F' \gets \emptyset$\;
		$A' \gets \{{a}, Q', q_d , \sigma', F' \}$\;
		\ForEach{$i \in [1,d]$}{
			\If{$q_i \in F$ and isPeriodic($A,i,d$)}{
				$F' \gets F' \cup [q_i]$
			}
		}
		\KwRet $A'$
	}
	\Fn{isPeriodic($A = \{{a}, Q, q_I , \sigma, F \}$: unary DFA, integer $d$, integer $i$)}{
		$pos \gets (i + d) ~mod~ |A|$\;
		\While{$pos \not= i$}{
			\If{$q_{pos} \not\in F$}{
				\KwRet false\;
			}
			$pos \gets (pos + d) ~mod~ |A|$
		}
	    \KwRet true\;
	}
	\caption{Algorithm for greedily computing an \orDecomp for unary DFAs and returning the factors.}
\end{algorithm}
This algorithm finds more factors than required since it also finds the multiples of the maximal divisors.
In contrast, not all found factors are required to form the decomposition and we only want to add factors, which change the decomposition.
In our example in Figure \ref{fig:short-factors} we find $A_2$ and $A_4$, but $A_2$ is fully sufficient for decomposing the \DFA $A$.
By iterating over all possible factors ordered by size, we can greedily add factors, which are required to form the decomposition.
To address the problem that most of the labels do not have proper decompositions in the mathematical sense, we will also consider a set of smaller automata that do not cover every value of a decomposition.
For this, we want to keep track of the outliers of each factor and the decomposition itself.
Regarding explainability, it should be of preference, to have a small factor but a couple of outliers, in comparison to a long factor, and even have a decomposition with hard outliers, e.g. values that cannot be covered by a decomposition.
In this case, a decomposition including outliers is also preferred.

\section{Problem Generalization}
The original problem was solvable in \LogSpace, but by extending the problem to finding the shortest possible factors, we face a different challenge.
Finding a valid decomposition is possible in \LogSpace but selecting a minimal amount of given factors needed to be a valid decomposition is not.
This problem can be generalized for a given set of factors as follows:
\begin{defn}[\sc{Min Factors Decomposition}]{\ \\}
	Input: A binary string $u$ with $\ell(u)= l$ and a set of binary strings $\mathcal{W} = \{w_1, w_2, \dots, w_n\}$ with $\ell(w_i) < l$ and $\ell(w_i)$ divides $l$ for $1 \leq i \leq n$ and an integer $k$.\\
	Question: Exists indices $i_1, i_2, \dots i_k$ such that
	$$w_{i_1}^{l / \ell(w_{i_1})} \lor w_{i_2}^{l / \ell(w_{i_2})} ~\dots~ \lor w_{i_k}^{l / \ell(w_{i_k})} = u $$
\end{defn}

To find lower bounds for this novel problem, we are going to reduce the {\sc{Set Cover}} problem, known to be NP-complete, to our novel {\sc{Min Factors Decomposition}} problem, using a polynomial time reduction.

\begin{defn}[\sc{Set Cover}]{\ \\}
	Input: A set of elements $U = \{u_1, u_2, \dots , u_n\}$. A set $\mathcal{C} = \{C_1, C_2, \dots , C_m\}$ where $C_i \subseteq U ~\forall~ C_i \in \mathcal{C}$ and an integer $k$.\\
	Question: Exists a set $\mathcal{O} \subseteq \mathcal{C}$ of size  at most $k$ such that $\underset{C_i \in \mathcal{O}}{\bigcup}C_i = U$.
\end{defn}
To reduce the {\sc{Set Cover}} problem to our novel problem, we create an instance as follows.
For the universe $U = \{u_1, u_2, \dots, u_n\}$ we will construct a binary string $u= 1^{2|U|}$ with length $\ell(u) = 2|U|$. For each subset of $\mathcal{C} = \{C_1, C_2, \dots, C_m\}$ we create a word $w_i$ such that $w_i[j] = 1$ iff $u_j \in C_i$. 

Assume a solution to the {\sc{Min Factors Decomposition}} problem $i_1, i_2, \dots, i_k$ that chooses from the words $w_i$ to form $u$, then the corresponding subsets $C_{i_1}, C_{i_2}, \dots, C_{i_k}$ in the constructed {\sc{Set Cover}} instance cover the entire universe $U$.
Assume there exists an element $u_x \in U$ with $u_x \not \in C_{i_k} ~\forall~ i_1, i_2, \dots, i_k$.
This implies that there is no $w_{i_k} ~\forall~ i_1, i_2, \dots, i_k$ with $w_{i_k}[x]=1$ which is in contradiction to the found solution with $w_{i_1}^{l / \ell(w_{i_1})} \lor w_{i_2}^{l / \ell(w_{i_2})} ~\dots~ \lor w_{i_k}^{l / \ell(w_{i_k})} = u = 1^{2|U|}$.
This means that $u_x$ cannot exist and we found a {\sc{Set Cover}} of size $k$.

If the {\sc{Set Cover}} problem has a solution $\mathcal{O} \subseteq \mathcal{C}, |\mathcal{O}|=k$ with $\bigcup_{C_i \in O} C_i = U$, then $w_{i_1}^{l / \ell(w_{i_1})} \lor w_{i_2}^{l / \ell(w_{i_2})} ~\dots~ \lor w_{i_k}^{l / \ell(w_{i_k})}$ is a solution to the {\sc{Min Factors Decomposition}} problem.
Assume $w_{i_1}^{l / \ell(w_{i_1})} \lor w_{i_2}^{l / \ell(w_{i_2})} ~\dots~ \lor w_{i_k}^{l / \ell(w_{i_k})} \not = u$, that implies there is at least one position $x$ where $(w_{i_1}^{l / \ell(w_{i_1})} \lor w_{i_2}^{l / \ell(w_{i_2})} ~\dots~ \lor w_{i_k}^{l / \ell(w_{i_k})})[x] \not= u[x] $.
This is in contradiction to the construction as there has to be a $C_{i_x} \in \mathcal{O}$ with $u_x \in C_{i_x}$ and therefore a word $w_{i_x}[x]=1$. This reduction demonstrates that solving the original problem is as hard as solving the {\sc{Set Cover}} problem.


\section{Fourier Transform}
\label{ch:novel-algos:fourier}
Finding shorter factors that just the maximal divisors should already increase the explainability but consider the following example from Figure \ref{fig:fourier-transform-a}.
Factor $A_4$ alone would suffice to cover the original \DFA $A$ but most of the final states are already covered by the smaller factor $A_2$.
Consider states $q_1, q_3 \dots$ which are covered by both factors, which is not required.
We now can remove all the states from $A_4$ which are already covered by $A_2$ and this results in 2 Factors with each having just one final state.
Of course, there might be multiple states which are not part of any other smaller factors, but any factor of an or-decomposition can be replaced by multiple factors of the same length, each with $|F_{B_i}| = 1 ~\forall~ (B_i)_{1 \leq i \leq k}$.
Each factor only having a single final state further increases explainability as it allows for each value to be represented as the position and the size of the factor or the periodicity, e.g. instead of a binary label, a list of integer tuples could represent the label.
For a comparison between single or multiple binary labels and a list of tuples with the factors, a detailed examination including human-computer interaction would be required.

\begin{figure}[h]
	\begin{minipage}[t]{\textwidth}
		\centering
		\begin{tikzpicture}[shorten >=1pt,node distance=1.5cm,on grid,auto] 
			\node[state,initial] (q_0)   {$q_0$}; 
			\node[state,accepting] (q_1) [ right=of q_0] {$q_1$}; 
			\node[state,accepting] (q_2) [ right=of q_1] {$q_2$}; 
			\node[state,accepting] (q_3) [ right=of q_2] {$q_3$};
			\node[state](q_4) [ right=of q_3] {$q_4$};
			\node[state,accepting] (q_5) [ right=of q_4] {$q_5$};
			\node[state,accepting] (q_6) [ right=of q_5] {$q_6$};
			\node[state,accepting] (q_7) [ right=of q_6] {$q_7$};
			\path[->] 
			(q_0) edge  node {} (q_1)
			(q_1) edge  node {} (q_2)
			(q_2) edge  node {} (q_3)
			(q_3) edge  node {} (q_4)
			(q_4) edge  node {} (q_5)
			(q_5) edge  node {} (q_6)
			(q_6) edge  node {} (q_7)
			(q_7) edge[bend right, above]  node {} (q_0);
		\end{tikzpicture}		
	\end{minipage}
	\begin{minipage}[b]{0.39\textwidth}
		\centering
		\begin{tikzpicture}[shorten >=1pt,node distance=1.5cm,on grid,auto] 
			\node[state,initial] (q_0)   {$q_0$}; 
			\node[state,accepting] (q_1) [right=of q_0] {$q_1$}; 
			\path[->] 
			(q_0) edge  node {} (q_1)
			(q_1) edge[bend right, above]  node {} (q_0);
		\end{tikzpicture}
	\end{minipage}
	\begin{minipage}[b]{0.59\textwidth}
		\centering
		\begin{tikzpicture}[shorten >=1pt,node distance=1.5cm,on grid,auto] 
			\node[state,initial] (q_0)   {$q_0$}; 
			\node[state,accepting] (q_1) [right=of q_0] {$q_1$}; 
			\node[state,accepting](q_2) [right=of q_1] {$q_2$};
			\node[state,accepting](q_3) [right=of q_2] {$q_3$};
			\path[->] 
			(q_0) edge  node {} (q_1)
			(q_1) edge  node {} (q_2)
			(q_2) edge  node {} (q_3)
			(q_3) edge[bend right, above]  node {} (q_0);
		\end{tikzpicture}
	\end{minipage}
	\caption{The DFA $A$ and its overlapping factors $A_2$ \& $A_4$}
	\label{fig:fourier-transform-a}
\end{figure}

\begin{figure}[h]
\begin{minipage}[b]{0.39\textwidth}
	\centering
	\begin{tikzpicture}[shorten >=1pt,node distance=1.5cm,on grid,auto] 
		\node[state,initial] (q_0)   {$q_0$}; 
		\node[state,accepting] (q_1) [right=of q_0] {$q_1$}; 
		\path[->] 
		(q_0) edge  node {} (q_1)
		(q_1) edge[bend right, above]  node {} (q_0);
	\end{tikzpicture}
\end{minipage}
\begin{minipage}[b]{0.59\textwidth}
	\centering
	\begin{tikzpicture}[shorten >=1pt,node distance=1.5cm,on grid,auto] 
		\node[state,initial] (q_0)   {$q_0$}; 
		\node[state] (q_1) [right=of q_0] {$q_1$}; 
		\node[state,accepting](q_2) [right=of q_1] {$q_2$};
		\node[state](q_3) [right=of q_2] {$q_3$};
		\path[->] 
		(q_0) edge  node {} (q_1)
		(q_1) edge  node {} (q_2)
		(q_2) edge  node {} (q_3)
		(q_3) edge[bend right, above]  node {} (q_0);
	\end{tikzpicture}
\end{minipage}
\caption{The Fourier transformed factors $A_2$ \& $A_4$}
\label{fig:fourier-transform-b}
\end{figure}
Of course, this would also greatly increase the amount of factors required for a valid decomposition, and in turn, could hurt performance.
In general, the greedy approach of combining factors of increasing size should still suffice.

\section{Relaxation of Requirements}
\label{ch:novel-algos:relaxation}
So far we only considered decompositions where the union over all factors $B_i$ results in exactly the original language, $L(A) = \cup_{1\leq i \leq k} L(B_i)$, and all factors $B_i$ in the decomposition satisfy $|B_i| < |A|$.
Since our goal is not to find decompositions of minimal width but to find decomposition such that the explainability is maximized, we can relax the requirements to achieve greater explainability.
If we allow for factors of original size $|B_i| \leq |A|$, we can find a factor of the original size, which covers all values not covered by a factor so far.
The values only covered by this final factor $B_k$ but not by any other can be considered hard outliers and it allows for a decomposition of any \DFA.
This is not properly defined for \DFAs but it makes sense in the context of explainable labels.
Additionally, we may allow for $L(A) \supseteq \cup_{1\leq i \leq k} L(B_i)$ and use the precision for a decomposition with $L(A) \not = \cup_{1\leq i \leq k} L(B_i)$ as $precision(\cup_{1\leq i \leq k}~ B_i) = \frac{|F_A| - out\{B_1\dots B_k\}}{|F_A|}$ used in the metric, and allow for a decomposition to be valid if a certain precision is reached.

\section{Delta Window as Preprocessing or During Folding}
\label{ch:novel-algos:delta-window}
Working with real-world data always poses a challenge as it might be very large or contain measurement errors.
The longer a label and therefore the corresponding automata gets, it becomes less and less likely that a valid folding of the automata exists.
To mitigate this problem, we implemented a delta window as a preprocessing as well as during the folding step of the algorithm.
The preprocessing changes the input data in a way that for each set value in the label, it gets extended to the desired delta window size.
This increases the likelihood of e.g. a valid folding, but in turn, increases the number of values to cover overall. On the contrary, the delta window during folding does not change the input, but instead, a folding is considered valid, if a set value folds onto another by some delta window.
The effectiveness of the delta window approach will be evaluated in Section \ref{ch:Evaluation:explainability}.

\section{EPG Graph Creation}
\label{ch:novel-algos:ept-graph}
TODO: describe collection of covers into single EPG graph with multiedges
%%% Local Variables: 
%%% mode: latex
%%% TeX-master: "thesis"
%%% End: 