\chapter{Explainability}
%%% Local Variables: 
%%% mode: latex
%%% TeX-master: "thesis"
%%% End: 

Understanding and interpreting labels in edge periodic temporal graphs is essential for various applications, such as network analysis, system monitoring, and predictive modeling. However, assessing the ease with which humans can comprehend these labels presents a unique challenge. In this context, we propose a comprehensive metric to measure the \enquote{explainability} of such labels, taking into account multiple factors that influence their possibility to interpret.

\section{Explainability Metric}
The comprehensive nature of the proposed metric is crucial. By considering factors like decomposition structure, periodicity, and decomposition width, it offers a holistic evaluation of label explainability. A standardized metric facilitates comparative analysis across different graphs and so this comparison allows for the selection of methods and different parameters in the algorithm to make it more understandable by humans. For a \DFA $A$, and its decomposition $(B_i)_{1 \leq i \leq k}$, we consider:

\textbf{Decomposition Structure} ($DS = \sum\limits_{factor~ B_i}\frac{|B_i|}{\text{|A|}} \cdot \frac{out_{\{B_1,\dots,B_i\}}}{|F_A|}$)

The decomposition structure takes into account whether the label is presented as a single, continuous binary string or is split into multiple, shorter labels. Labels with multiple shorter segments may facilitate explanation, as they enable a more granular understanding of connectivity changes at different time steps. For example, dividing the label into daily or weekly segments could aid in interpreting temporal patterns. This generally implies more factors are easier to understand than few factors.

\textbf{Precision} ($precision = \frac{|F_A| - out_{\{B_1,\dots,B_k\}}}{|F_A|}$)

Precision refers to the regularity of patterns in the label across different time steps. A label that exhibits a clear and consistent periodicity allows human observers to anticipate when changes in connectivity occur. This precision aids in comprehending the temporal dynamics of the graph. Few outliers which cannot be covered by any factor imply a high precision.

\textbf{Size} ($k$)

The decomposition size is a fundamental factor in assessing explainability. A highly decomposed label, often implies a more concise representation. A collection of labels with distinct information is generally easier for humans to understand, as it conveys information succinctly. Very long labels may overwhelm human observers with excessive detail.


\section{Explainability Measurement}

To measure the proposed explainability metric for edge periodic temporal graphs, a systematic approach is employed, utilizing real-world data from face-to-face (f2f) graphs. Existing algorithms as well as novel approaches designed for edge periodic temporal graph construction are used and the resulting decompositions are evaluated using the described metrics. For a more complete analysis of the quality of the measured explainability, a study with a human computer interaction focus would be required but is out of scope for this project.

TODO: give some examples and estimates for the given metrics